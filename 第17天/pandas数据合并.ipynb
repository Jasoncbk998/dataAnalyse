{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便维护，一般公司的数据在数据库内都是分表存储的，比如用一个表存储所有用户的基本信息，一个表存储用户的消费情况。所以，在日常的数据处理中，经常需要将两张表拼接起来使用，这样的操作对应到SQL中是join，在Pandas中则是用merge来实现。这篇文章就讲一下merge的主要原理。\n",
    "\n",
    "上面的引入部分说到merge是用来拼接两张表的，那么拼接时自然就需要将用户信息一一对应地进行拼接，所以进行拼接的两张表需要有一个共同的识别用户的键（key）。总结来说，整个merge的过程就是将信息一一对应匹配的过程，下面介绍merge的四种类型，分别为`inner`、`left`、`right`和`outer`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge() 函数的法格式如下：\n",
    "`pd.merge(\n",
    "    left,\n",
    "    right,\n",
    "    how: str = 'inner',\n",
    "    on=None,\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index: bool = False,\n",
    "    right_index: bool = False,\n",
    "    sort: bool = False,\n",
    "    suffixes=('_x', '_y'),\n",
    "    copy: bool = True,\n",
    "    indicator: bool = False,\n",
    "    validate=None,\n",
    ")`\n",
    "- `left/right` \t两个不同的 DataFrame 对象。\n",
    "- `how` \t要执行的合并类型，从 {'left', 'right', 'outer', 'inner'} 中取值，默认为“inner”内连接。\n",
    "- `on` 指定用于连接的键（即列标签的名字），该键必须同时存在于左右两个 DataFrame 中，如果没有指定，并且其他参数也未指定， 那么将会以两个 DataFrame 的列名交集做为连接键。\n",
    "- `left_on` \t指定左侧 DataFrame 中作连接键的列名。该参数在左、右列标签名不相同，但表达的含义相同时非常有用。\n",
    "- `right_on` \t指定左侧 DataFrame 中作连接键的列名。\n",
    "- `left_index` \t布尔参数，默认为 False。如果为 True 则使用左侧 DataFrame 的行索引作为连接键\n",
    "- `right_index` \t布尔参数，默认为 False。如果为 True 则使用左侧 DataFrame 的行索引作为连接键\n",
    "- `sort` \t布尔值参数， False，则按照 how 给定的参数值进行排序。设置为True，它会将合并后的数据进行排序；\n",
    "- `suffixes` \t字符串组成的元组。当左右 DataFrame 存在相同列名时，通过该参数可以在相同的列名后附加后缀名，默认为('_x','_y')。\n",
    "- `copy` \t默认为 True，表示对数据进行复制。\n",
    "\n",
    "> 注意：Pandas 库的 merge() 支持各种内外连接，与其相似的还有 join() 函数（默认为左连接）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、inner\n",
    "\n",
    "merge的`inner`的类型称为内连接，它在拼接的过程中会取两张表的键（key）的交集进行拼接。什么意思呢？\n",
    "\n",
    "下面以图解的方式来一步一步拆解。\n",
    "\n",
    "首先我们有以下的数据，左侧和右侧的数据分别代表了用户的基础信息和消费信息，连接两张表的键是userid。\n",
    "<img src=\"images/20220427222127.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({\n",
    "                     \"userid\":['a', 'b', 'c', 'd'], \n",
    "                     \"age\":[23, 46, 32, 19]\n",
    "                    })\n",
    "df_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame({\n",
    "        \"userid\":['a', 'c'],\n",
    "        \"payment\":[2000, 3500]\n",
    "    })\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.merge(df_2,on='userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2, on='userid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过程图解：\n",
    "\n",
    "①取两张表的键的交集，这里df_1和df_2的userid的交集是{a,c}\n",
    "\n",
    "<img src=\"images/20220427222905.png\" style=\"width:50%\"/>\n",
    "\n",
    "②对应匹配\n",
    "\n",
    "<img src=\"images/20220427223017.png\" style=\"width:50%\"/>\n",
    "\n",
    "③结果\n",
    "\n",
    "<img src=\"images/20220427223053.png\" style=\"width:40%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相信整个过程并不难理解，上面演示的是同一个键下，两个表对应只有一条数据的情况（一个用户对应一条消费记录），那么，如果一个用户对应了多条消费记录的话，那又是怎么拼接的呢？\n",
    "\n",
    "假设现在的数据变成了下面这个样子，在df_2中，有两条和a对应的数据："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/20220427223150.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样用inner的方式进行merge：\n",
    "df_1 = pd.DataFrame({\n",
    "                     \"userid\":['a', 'b', 'c', 'd'], \n",
    "                     \"age\":[23, 46, 32, 19]\n",
    "                    })\n",
    "\n",
    "df_2 = pd.DataFrame({\n",
    "        \"userid\":['a', 'c','a', 'd'],\n",
    "        \"payment\":[2000, 3500, 500, 1000]\n",
    "    })\n",
    "pd.merge(df_1, df_2, on=\"userid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个过程除了对应匹配阶段，其他和上面基本都是一致的。\n",
    "\n",
    "过程图解：\n",
    "\n",
    "①取两张表的键的交集，这里df_1和df_2的userid的交集是{a,b,c}\n",
    "\n",
    "<img src=\"images/20220427223448.png\" style=\"width:50%\"/>\n",
    "\n",
    "②对应匹配时，由于这里的a有两条对应的消费记录，故在拼接时，会将用户基础信息表中a对应的数据复制多一行来和右边进行匹配。\n",
    "\n",
    "<img src=\"images/20220427223622.png\" style=\"width:50%\"/>\n",
    "\n",
    "③结果\n",
    "\n",
    "<img src=\"images/20220427223701.png\" style=\"width:40%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、left 和right\n",
    "\n",
    "'left'和'right'的merge方式其实是类似的，分别被称为左连接和右连接。这两种方法是可以互相转换的，所以在这里放在一起介绍。\n",
    "\n",
    "    'left'\n",
    "\n",
    "merge时，以左边表格的键为基准进行配对，如果左边表格中的键在右边不存在，则用缺失值NaN填充。\n",
    "\n",
    "    'right'\n",
    "\n",
    "merge时，以右边表格的键为基准进行配对，如果右边表格中的键在左边不存在，则用缺失值NaN填充。\n",
    "\n",
    "什么意思呢？用一个例子来具体解释一下，这是演示的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/20220427223824.png\" style=\"width:60%\"/>\n",
    "\n",
    "现在用'left'的方式进行merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({\n",
    "                     \"userid\":['a', 'b', 'c', 'd'], \n",
    "                     \"age\":[23, 46, 32, 19]\n",
    "                    })\n",
    "\n",
    "df_2 = pd.DataFrame({\n",
    "        \"userid\":['a', 'c','e'],\n",
    "        \"payment\":[2000, 3500, 600]\n",
    "    })\n",
    "pd.merge(df_1, df_2,how='left', on=\"userid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过程图解：\n",
    "\n",
    "①以左边表格的所有键为基准进行配对。图中，因为右表中的e不在左表中，故不会进行配对。\n",
    "\n",
    "<img src=\"images/20220427224107.png\" style=\"width:40%\"/>\n",
    "\n",
    "②若右表中的payment列合并到左表中，对于没有匹配值的用缺失值NaN填充\n",
    "<img src=\"images/20220427224237.png\" style=\"width:40%\"/>\n",
    "\n",
    "对于'right'类型的merge和'left'其实是差不多的，只要把两个表格的位置调换一下，两种方式返回的结果就是一样的（），如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2,how='right', on=\"userid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、outer\n",
    "\n",
    "'outer'是外连接，在拼接的过程中它会取两张表的键（key）的并集进行拼接。看文字不够直观，还是上例子吧！\n",
    "\n",
    "还是使用上方用过的演示数据\n",
    "<img src=\"images/20220427223824.png\" style=\"width:70%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2,how='outer',on='userid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图解如下：\n",
    "\n",
    "①取两张表键的并集，这里是{a,b,c,d,e}\n",
    "\n",
    "<img src=\"images/20220427224545.png\" style=\"width:40%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_index函数详解\n",
    "专门用来将某一列设置为index的方法\n",
    "`DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)`\n",
    "- `keys` : 要设置为索引的列名（如有多个应放在一个列表里）\n",
    "- `drop` : 将设置为索引的列删除，默认为True\n",
    "- `append` : 是否将新的索引追加到原索引后（即是否保留原索引），默认为False\n",
    "- `inplace` : 是否在原DataFrame上修改，默认为False\n",
    "- `verify_integrity` : 是否检查索引有无重复，默认为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
    "                   'year': [2012, 2014, 2013, 2014],\n",
    "                   'sale': [55, 40, 84, 31]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将索引设置为“month”列： \n",
    "df.set_index('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将month列设置为index之后，并保留原来的列\n",
    "df.set_index('month',drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留原来的index列\n",
    "df.set_index('month', append=True)\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用inplace参数取代原来的对象\n",
    "df.set_index('month', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过新建Series并将其设置为index\n",
    "df.set_index(pd.Series(range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas去重函数 ：drop_duplicates()\n",
    "“去重”通过字面意思不难理解，就是删除重复的数据。在一个数据集中，找出重复的数据删并将其删除，最终只保存一个唯一存在的数据项，这就是数据去重的整个过程。删除重复数据是数据分析中经常会遇到的一个问题。通过数据去重，不仅可以节省内存空间，提高写入性能，还可以提升数据集的精确度，使得数据集不受重复数据的影响。\n",
    "\n",
    "Panda DataFrame 对象提供了一个数据去重的函数 drop_duplicates()\n",
    "`DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)`\n",
    "\n",
    "- `subset`：表示要进去重的列名，默认为 None。\n",
    "- `keep`：有三个可选参数，分别是 first、last、False，默认为 first，表示只保留第一次出现的重复项，删除其余重复项，last 表示只保留最后一次出现的重复项，False 则表示删除所有重复项\n",
    "- `inplace`：布尔值参数，默认为 False 表示删除重复项后返回一个副本，若为 Ture 则表示直接在原数据上删除重复项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
    "    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
    "    'rating': [4, 4, 3.5, 15, 5]\n",
    "\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认情况下，它会基于所有列删除重复的行\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除特定列上的重复项，使用子集\n",
    "df.drop_duplicates(subset=['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复项并保留最后出现的项，请使用“保留”。\n",
    "df.drop_duplicates(subset=['brand', 'style'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  tolist()\n",
    "pandas的tolist()函数用于将一个系列或数据帧中的列转换为列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(df['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
